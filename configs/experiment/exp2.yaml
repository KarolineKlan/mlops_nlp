hydra:
  run:
    dir: .

model:
  name: "Experiment2"
  learning_rate: 0.001
  dropout: 0.2
  dropout_active: False

trainer:
  epochs: 10
  log_interval: 10
  save_interval: 1
  wandb_project: "dtu_mlops"
  train_seed: 42
  wandb_team: "spicy-mlops"
  sweep: True
  sweep_config: {"method": "bayes", "metric": {"name": "val_loss", "goal": "minimize"},"parameters": 
{"batch_size": {"values":[16,32]},"learning_rate": {"min":0.001,"max":0.01},},
}

data:
  model_name: "distilbert-base-uncased"
  data_path: "data/processed"
  train_size: 500
  data_seed: 42
  batch_size: 16
  test_ratio: 0.2
  val_ratio: 0.2
  force: False
  
  input_dim: 768  

visualize:
  model_checkpoint: "models/SimpleModel.ckpt"
  figure_name: "embedding_figure.png"
